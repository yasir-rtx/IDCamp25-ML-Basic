# Data Collecting  
## Fondasi Utama Machine Learning

## 1. Peran Data Collecting dalam Machine Learning

Data collecting adalah **tahap pertama dan paling fundamental** dalam alur kerja machine learning. Tanpa data yang tepat dan berkualitas, model secanggih apa pun tidak akan mampu menghasilkan prediksi yang andal.

> **Garbage In, Garbage Out**  
Kualitas output model secara langsung bergantung pada kualitas data yang digunakan.

Clive Humby menggambarkan data sebagai *the new oil*: berharga, tetapi hanya bernilai jika diproses dan dimurnikan dengan benar.

---

## 2. Mengapa Data Collecting Sangat Penting

### 2.1 Menentukan Akurasi Model
- Data yang relevan dan cukup membantu model memahami pola dengan lebih baik
- Data berkualitas rendah (noise, outlier) menurunkan performa model

### 2.2 Mencegah Bias
- Dataset tidak seimbang → model bias
- Representasi data yang beragam → model lebih adil dan general

### 2.3 Mengakomodasi Variasi Dunia Nyata
- Dunia nyata tidak statis
- Model perlu dilatih dengan data dari berbagai kondisi dan skenario

---

## 3. Jenis Sumber Data

### 3.1 Data Internal
- Data operasional perusahaan (penjualan, pelanggan, log aplikasi)
- Biasanya terstruktur dan relevan dengan tujuan bisnis

### 3.2 Data Eksternal
- Data publik pemerintah
- Data hasil web scraping
- Data berbayar dari penyedia data

### 3.3 Data Sintetis
- Data buatan yang meniru karakteristik data nyata
- Berguna saat data asli sulit atau mahal didapatkan

### 3.4 Data dari Pengguna
- Interaksi pengguna
- Ulasan, perilaku klik, riwayat pencarian
- Sangat bernilai untuk produk digital

---

## 4. Cara Mengumpulkan Data

### 4.1 Ekstraksi Data (Scraping / API)
- Mengambil data dari website atau layanan online
- Cocok untuk data publik dan terstruktur

### 4.2 Membuat Dataset Sendiri
- Survei
- Aplikasi internal
- Penggabungan beberapa sumber data
- Kontrol penuh atas struktur dan kualitas data

### 4.3 Menggunakan Dataset yang Sudah Ada
- Dataset publik atau open-source
- Menghemat waktu dan biaya
- Perlu perhatian pada lisensi dan konteks data

---

## 5. Tahapan Umum Data Collecting

1. **Menentukan Kebutuhan Data**
   - Tujuan analisis atau prediksi
   - Jenis data dan skala data

2. **Memilih Sumber Data**
   - Internal, eksternal, atau kombinasi
   - Pertimbangkan reliabilitas dan relevansi

3. **Mengumpulkan dan Menyimpan Data**
   - Melalui API, file, database, scraping, survei
   - Pastikan keamanan dan format data

4. **Validasi dan Pembersihan Data**
   - Mengatasi missing value
   - Menghapus duplikasi dan anomali
   - Tahap krusial sebelum modeling

---

## 6. Menentukan Sumber Dataset (Dataset Discovery)

Menemukan dataset yang tepat adalah skill penting bagi machine learning engineer dan data scientist.

### 6.1 UCI Machine Learning Repository
- Salah satu repositori dataset ML tertua dan paling kredibel
- Dataset lintas domain
- Dokumentasi lengkap (atribut, lisensi, sumber)
- Gratis dan sangat cocok untuk riset & validasi model

**Cocok untuk:** pembelajaran fundamental dan eksperimen algoritma

---

### 6.2 Kaggle Datasets
- Platform komunitas data science terbesar
- Dataset + kompetisi berbasis masalah nyata
- Notebook Python/R langsung di browser
- Forum diskusi dan kursus gratis

**Cocok untuk:**  
- Belajar end-to-end ML  
- Benchmark skill  
- Simulasi kasus industri

---

### 6.3 Google Dataset Search
- Mesin pencari khusus dataset
- Mengindeks metadata dataset dari berbagai platform
- Memudahkan pencarian dataset lintas domain

**Cocok untuk:** eksplorasi dataset skala besar dan lintas institusi

---

### 6.4 TensorFlow Datasets (TFDS)
- Dataset siap pakai khusus TensorFlow
- Sudah terstruktur (train / validation / test)
- Terintegrasi dengan `tf.data.Dataset`
- Mendukung preprocessing dan augmentasi

**Cocok untuk:** deep learning, computer vision, dan NLP berbasis TensorFlow

---

### 6.5 US Government Data (Data.gov)
- Data publik dari pemerintah AS
- Meliputi kesehatan, ekonomi, pendidikan, lingkungan
- Gratis dan transparan

**Cocok untuk:** data skala nasional dan studi kebijakan publik

---

### 6.6 Satu Data Indonesia
- Portal resmi data publik Indonesia
- Mendukung keterbukaan dan interoperabilitas data pemerintah
- Sesuai regulasi keterbukaan informasi publik

**Cocok untuk:** analisis sosial, ekonomi, dan kebijakan berbasis Indonesia

---

### 6.7 Open Data Pemerintah Jawa Barat
- Portal data terbuka tingkat provinsi
- Data akurat, terstandarisasi, dan berkelanjutan

**Cocok untuk:** studi regional dan localized ML use case

---

## 7. Insight Penting untuk Target Level Expert

### Insight 1 — Data Strategy Lebih Penting dari Model
Expert berpikir:
- *Data apa yang paling bernilai?*
- *Apa yang tidak perlu dikumpulkan?*

Lebih banyak data ≠ selalu lebih baik data.

---

### Insight 2 — Bias Dimulai dari Tahap Collecting
Bias bukan hanya masalah algoritma, tetapi:
- Cara data dikumpulkan
- Siapa yang terwakili dan siapa yang tidak

---

### Insight 3 — Data Collecting adalah Iteratif
Di level profesional:
- Data collecting ≠ one-time process
- Model → evaluasi → kebutuhan data baru → collect ulang

---

### Insight 4 — Pahami Konteks, Bukan Hanya Format
Expert tidak hanya melihat:
- Kolom
- Tipe data  
tetapi juga:
- Cara data dihasilkan
- Potensi error sistemik
- Limitasi dunia nyata

---

## 8. Studi Kasus Singkat: Prediksi Harga Rumah

Sumber data:
- Website properti: harga, lokasi, ukuran, tahun bangunan
- Data pemerintah: suku bunga, tren ekonomi
- Survei: preferensi pembeli

Alur:
- Data dikumpulkan → dibersihkan → divalidasi
- Digunakan untuk melatih model prediksi harga
- Hasil: estimasi harga yang lebih akurat dan realistis

---

## 9. Penutup

Data collecting adalah **pondasi utama** dalam machine learning. Kesalahan di tahap ini akan berdampak ke seluruh pipeline, sedangkan data yang baik dapat menyederhanakan tahap modeling secara signifikan.

Langkah menuju expert:
- Fokus pada kualitas data
- Bangun intuisi terhadap sumber dan bias data
- Anggap data sebagai aset strategis, bukan sekadar input

Siap melangkah ke tahap berikutnya.
